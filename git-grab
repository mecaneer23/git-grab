#!/usr/bin/env python3
# pylint: disable=invalid-name
"""
`git-grab` emulates `git clone`, grabbing all of the files from a provided git repository.
However, it ignores all git history and doesn't grab the git files.
"""

from argparse import ArgumentParser, Namespace
from io import BytesIO
from json import loads
from pathlib import Path
from re import findall
from sys import exit as sys_exit
from urllib.request import urlopen


def parse_args() -> Namespace:
    """
    Parse command line arguments.
    Use --help for help or see the
    README for more information.
    """
    parser = ArgumentParser()
    parser.add_argument(
        "url",
        type=str,
    )
    parser.add_argument(
        "path",
        type=str,
        nargs="?",
        default="",
    )

    return parser.parse_args()


def get_url_domain(url: str) -> str:
    """Get domain portion of url"""
    return url.split("//", maxsplit=1)[1].split("/")[0]


def get_url_user_name(url: str) -> str:
    """
    Get username portion of url

    GitHub specific
    """
    return url.split("/")[-2]


def get_url_repo_name(url: str) -> str:
    """
    Get repository portion of url

    GitHub specific
    """
    return url.rsplit("/", maxsplit=1)[1]


def md_line_to_py(line: str) -> str:
    """
    Convert a single list item from a
    MarkDown formatted list to a Python string.
    """
    return findall(r"\[([^\)]+)\]", line.split(" ", maxsplit=1)[1])[0]


def md_list_to_py(
    first_line_idx: int,
    last_line_idx: int,
    filename: Path = Path("README.md"),
) -> list[str]:
    """
    Convert a markdown list to a python list.

    Inspired from https://github.com/mecaneer23/Ndo/blob/main/src/md_to_py.py
    md_table_to_lines() function
    """

    with filename.open(encoding="utf-8") as file:
        lines = file.readlines()[first_line_idx - 1 : last_line_idx - 1]

    return list(map(md_line_to_py, lines))


def get_default_branch(user_name: str, repo_name: str) -> str:
    """
    Make an api call to GitHub.
    Return the default branch for the provided repository.
    """
    with urlopen(f"https://api.github.com/repos/{user_name}/{repo_name}") as response:
        return loads(response.read().decode("utf-8"))["default_branch"]


def get_repo_files(user_name: str, repo_name: str, branch: str) -> list[str]:
    """
    Make an api call to GitHub.

    Return a list of all files (including paths) in the repository.
    """
    with urlopen(
        f"https://api.github.com/repos/{user_name}/{repo_name}/git/trees/{branch}?recursive=1"
    ) as response:
        raw_json = loads(response.read().decode("utf-8"))

    output: list[str] = []
    for file_or_folder in raw_json["tree"]:
        if file_or_folder["type"] == "tree":
            continue
        output.append(file_or_folder["path"])
    return output


def get_download_url(user_name: str, repo_name: str, filename: str) -> str:
    """
    Make an api call to GitHub.
    Return the url to download the provided file as a raw file.
    """
    with urlopen(
        f"https://api.github.com/repos/{user_name}/{repo_name}/contents/{filename}"
    ) as response:
        return loads(response.read().decode("utf-8"))["download_url"]


def download_files(
    user_name: str, repo_name: str, files_list: list[str], output_path: Path
) -> None:
    """
    Iterate through the provided files.

    Generate a url based on the arguments. Download each file.

    Write downloaded files to provided output path and return nothing.
    """
    for file in files_list:
        with urlopen(
            get_download_url(user_name, repo_name, file),
        ) as response, output_path.joinpath(file).open("wb") as output_file:
            length = response.getheader("content-length")
            block_size = max(4096, int(length) // 100) if length else 1_000_000
            output_buffer = BytesIO()
            size = 0
            while True:
                block_buffer = response.read(block_size)
                if not block_buffer:
                    break
                output_buffer.write(block_buffer)
                size += len(block_buffer)
                if length:
                    print(
                        f"Downloading {file}: {int(size / int(length) * 100)}%",
                        end="\r",
                    )
            print()
            output_file.write(output_buffer.read())


def validate_url(url: str) -> None:
    """
    Try to validate the provided url using the list from the README.
    If the url is not valid, raise a ValueError.
    If the README is not available, do not validate and print warning.
    """
    try:
        implemented_urls = md_list_to_py(
            49,
            50,
            Path(__file__).parent.joinpath("README.md"),
        )
        if get_url_domain(url) not in implemented_urls:
            raise ValueError(
                f"Invalid url, valid urls are one of the following: {implemented_urls}"
            )
    except FileNotFoundError:
        print("Warning: unable to validate url domain")


def main() -> None:
    """
    Entry point for git-grab.

    Using command line arguments, download a repository from the internet.
    """
    args = parse_args()
    url: str = args.url
    str_path: str = args.path or get_url_repo_name(url)
    path: Path = Path(str_path)

    validate_url(url)

    user_name = get_url_user_name(url)
    repo_name = get_url_repo_name(url)
    files = get_repo_files(
        user_name, repo_name, get_default_branch(user_name, repo_name)
    )

    try:
        path.mkdir()
    except FileExistsError:
        sys_exit(f"File exists: `{path}`. Try adding a path.")

    download_files(
        user_name,
        repo_name,
        files,
        path,
    )

    print(f"Successfully downloaded {len(files)} files to new folder `{path}`")


if __name__ == "__main__":
    main()
